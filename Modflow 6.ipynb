{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MODFLOW 6 models from Geomodelr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Geomodelr webinar. Here we are going to explain how to load and run our models created and exported from Geomodelr. Furthemore, we will show how to get the results and save them in the _vtk_ file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this goal, we need the last version of flopy (3.2.12). Furthemore, we are using the vtk library, version 8.2.0 and numpy, version 1.16.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flopy is installed in D:\\Programas_Instalados\\Anaconda3\\envs\\advanced-math\\lib\\site-packages\\flopy\n",
      "numpy version 1.16.4\n",
      "flopy version 3.2.12\n",
      "json version 2.0.9\n",
      "vtk version 8.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import flopy\n",
    "import vtk\n",
    "import json\n",
    "from vtk.util import numpy_support\n",
    "\n",
    "print('numpy version {}'.format(np.__version__))\n",
    "print('flopy version {}'.format(flopy.__version__))\n",
    "print('json version {}'.format(json.__version__))\n",
    "print(vtk.vtkVersion.GetVTKSourceVersion())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulation\n",
    "\n",
    "We define the name of the simulation and its location. On the other hand, we must to set the location of mf6.exe (including the executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'mf6_webinar' # Name of the study\n",
    "\n",
    "sim_location = 'D:/CompartidaVB/Modflow/Webinar_2019/modflow6/{}/'.format(file_name)\n",
    "exe_location = 'C:/WRDAPP/mf6.0.4/mf6.0.4/bin/mf6.exe' # mf6 exucatable location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we load the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading simulation...\n",
      "  loading simulation name file...\n",
      "  loading tdis package...\n",
      "  loading model gwf6...\n",
      "    loading package disu...\n",
      "    loading package riv...\n",
      "    loading package wel...\n",
      "    loading package npf...\n",
      "    loading package ic...\n",
      "    loading package oc...\n",
      "  loading ims package mf6_webinar...\n"
     ]
    }
   ],
   "source": [
    "sim = flopy.mf6.MFSimulation.load(sim_ws=sim_location , exe_name=exe_location)\n",
    "model = sim.get_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model packges: ['disu', 'riv_0', 'wel', 'npf', 'ic', 'oc']\n",
      "\n",
      "Simulation packges: dict_keys(['nam', 'tdis', 'ims'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_packages = model.package_names #All packages of the model\n",
    "print('Model packges: {}\\n'.format(model_packages))\n",
    "\n",
    "sim_packages = sim.package_key_dict.keys()\n",
    "print('Simulation packges: {}\\n'.format(sim_packages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISU Package\n",
    "It is the package that contains all the data about mesh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertices info:\n",
      "\n",
      "[(    0, 1067350.63, 1073405.91) (    1, 1067333.06, 1073406.41)\n",
      " (    2, 1067317.78, 1073393.55) ... (52117, 1066736.15, 1063707.81)\n",
      " (52118, 1066748.39, 1063707.81) (52119, 1066760.63, 1063707.81)]\n"
     ]
    }
   ],
   "source": [
    "disu = model.get_package('disu')\n",
    "\n",
    "print('Vertices info:\\n\\n{}'.format(disu.vertices.array)) # vertices array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells info:\n",
      "\n",
      "[(     0, 1067330.93, 1073391.66, 6,     6,     5,     4,     3, 2, 1, None, None, None, None)\n",
      " (     1, 1067330.93, 1073391.66, 6,     6,     5,     4,     3, 2, 1, None, None, None, None)\n",
      " (     2, 1067330.93, 1073391.66, 6,     6,     5,     4,     3, 2, 1, None, None, None, None)\n",
      " ...\n",
      " (339120, 1066766.75, 1063713.32, 4, 49512, 52120, 47448, 47449, None, None, None, None, None, None)\n",
      " (339121, 1066766.75, 1063713.32, 4, 49512, 52120, 47448, 47449, None, None, None, None, None, None)\n",
      " (339122, 1066766.75, 1063713.32, 4, 49512, 52120, 47448, 47449, None, None, None, None, None, None)]\n"
     ]
    }
   ],
   "source": [
    "print('Cells info:\\n\\n{}'.format(disu.cell2d.array)) # vertices array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conection info:\t[    -1      2     11 ... 339109 339110 339122]\n"
     ]
    }
   ],
   "source": [
    "print('Conection info:\\t{}'.format(disu.ja.array)) # vertices array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riv package\n",
    "This package contains all data about rivers: river nodes, conductance, stage and bottom of the rivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{internal}\n",
      "([((1080,), 2615.56543162, 30., 2613.56543162, 'cd_las_lara')\n",
      " ((1091,), 2603.10831491, 30., 2601.10831491, 'cd_las_lara')\n",
      " ((1103,), 2598.00491308, 30., 2596.00491308, 'cd_las_lara') ...\n",
      " ((9850,), 1918.98375071, 30., 1916.98375071, 'q._los_confines')\n",
      " ((330608,), 1916.61170247, 30., 1914.61170247, 'q._los_confines')\n",
      " ((330622,), 1920.30177343, 30., 1918.30177343, 'q._los_confines')])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "riv = model.get_package('riv')\n",
    "print(riv.stress_period_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wel package\n",
    "This package contains all data about wells: wells nodes, volumetric well rate and ther names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{internal}\n",
      "([((21427,), -18., 'w7') ((21428,), -18., 'w7') ((21429,), -18., 'w7')\n",
      " ((21430,), -18., 'w7') ((21431,), -18., 'w7') ((21432,), -18., 'w7')\n",
      " ((21433,), -18., 'w7') ((21434,), -18., 'w7') ((21435,), -18., 'w7')\n",
      " ((21436,), -18., 'w7') ((21437,), -18., 'w7') ((21438,), -18., 'w7')\n",
      " ((21439,), -18., 'w7') ((21440,), -18., 'w7') ((21441,), -18., 'w7')\n",
      " ((21442,), -18., 'w7') ((21443,), -18., 'w7') ((21444,), -18., 'w7')\n",
      " ((21445,), -18., 'w7') ((21446,), -18., 'w7') ((21447,), -18., 'w7')\n",
      " ((21470,), -17., 'w6') ((21471,), -17., 'w6') ((21472,), -17., 'w6')\n",
      " ((21473,), -17., 'w6') ((21474,), -17., 'w6') ((21475,), -17., 'w6')\n",
      " ((21476,), -17., 'w6') ((21477,), -17., 'w6') ((21478,), -17., 'w6')\n",
      " ((21479,), -17., 'w6') ((21480,), -17., 'w6') ((21481,), -17., 'w6')\n",
      " ((21482,), -17., 'w6') ((21483,), -17., 'w6') ((21484,), -17., 'w6')\n",
      " ((21520,), -16., 'w5') ((21521,), -16., 'w5') ((21522,), -16., 'w5')\n",
      " ((21523,), -16., 'w5') ((21524,), -16., 'w5') ((21525,), -16., 'w5')\n",
      " ((21526,), -16., 'w5') ((21527,), -16., 'w5') ((21536,), -15., 'w4')\n",
      " ((21537,), -15., 'w4') ((21538,), -15., 'w4') ((21539,), -15., 'w4')\n",
      " ((21540,), -15., 'w4') ((21541,), -15., 'w4') ((21542,), -15., 'w4')\n",
      " ((21543,), -15., 'w4') ((21544,), -15., 'w4') ((21545,), -15., 'w4')\n",
      " ((21546,), -15., 'w4') ((21547,), -15., 'w4') ((21548,), -15., 'w4')\n",
      " ((21549,), -15., 'w4') ((21550,), -15., 'w4') ((21551,), -15., 'w4')\n",
      " ((21552,), -15., 'w4') ((21553,), -15., 'w4') ((21576,), -14., 'w3')\n",
      " ((21577,), -14., 'w3') ((21594,), -13., 'w2') ((21595,), -13., 'w2')\n",
      " ((21596,), -13., 'w2') ((21597,), -13., 'w2') ((21598,), -13., 'w2')\n",
      " ((21599,), -13., 'w2') ((21600,), -13., 'w2') ((21601,), -13., 'w2')\n",
      " ((21602,), -13., 'w2') ((21603,), -13., 'w2') ((21604,), -13., 'w2')\n",
      " ((21605,), -13., 'w2') ((21606,), -13., 'w2') ((21607,), -13., 'w2')\n",
      " ((21608,), -13., 'w2') ((21609,), -13., 'w2') ((21610,), -13., 'w2')\n",
      " ((21632,), -12., 'w1') ((21633,), -12., 'w1') ((21634,), -12., 'w1')\n",
      " ((21635,), -12., 'w1') ((21636,), -12., 'w1') ((21637,), -12., 'w1')\n",
      " ((21638,), -12., 'w1') ((21639,), -12., 'w1') ((21640,), -12., 'w1')\n",
      " ((21641,), -12., 'w1') ((21642,), -12., 'w1')])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wel = model.get_package('wel')\n",
    "print(wel.stress_period_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMS package (Iterative Model Solution)\n",
    "This package contains the information related about numerical solver. This package is registers to simulation and it is assigned to each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package_name = mf6_webinar\n",
      "filename = mf6_webinar.ims\n",
      "package_type = ims\n",
      "model_or_simulation_package = simulation\n",
      "simulation_name = modflowsim\n",
      "\n",
      "Block options\n",
      "--------------------\n",
      "print_option\n",
      "{internal}\n",
      "(all)\n",
      "\n",
      "complexity\n",
      "{internal}\n",
      "(moderate)\n",
      "\n",
      "\n",
      "Block nonlinear\n",
      "--------------------\n",
      "outer_hclose\n",
      "{internal}\n",
      "(0.01)\n",
      "\n",
      "outer_maximum\n",
      "{internal}\n",
      "(50)\n",
      "\n",
      "\n",
      "Block linear\n",
      "--------------------\n",
      "inner_maximum\n",
      "{internal}\n",
      "(30)\n",
      "\n",
      "inner_hclose\n",
      "{internal}\n",
      "(0.01)\n",
      "\n",
      "linear_acceleration\n",
      "{internal}\n",
      "(cg)\n",
      "\n",
      "relaxation_factor\n",
      "{internal}\n",
      "(0.97)\n",
      "\n",
      "preconditioner_levels\n",
      "{internal}\n",
      "(8)\n",
      "\n",
      "preconditioner_drop_tolerance\n",
      "{internal}\n",
      "(0.0001)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ims = sim.get_package('ims')\n",
    "print(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of nonlinear interations: 50\n",
      "Maximum number of linear interations: 30\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of outer (nonlinear) iterations.\n",
    "print('Maximum number of nonlinear interations: {}'.format(ims.outer_maximum.get_data()))\n",
    "ims.outer_maximum.set_data(500)\n",
    "\n",
    "# Maximum number of inner (linear) iterations.\n",
    "print('Maximum number of linear interations: {}'.format(ims.inner_maximum.get_data()))\n",
    "ims.inner_maximum.set_data(130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of nonlinear interations: 500\n",
      "Maximum number of linear interations: 130\n"
     ]
    }
   ],
   "source": [
    "# Maximum number of outer (nonlinear) iterations.\n",
    "print('Maximum number of nonlinear interations: {}'.format(ims.outer_maximum.get_data()))\n",
    "\n",
    "# Maximum number of inner (linear) iterations.\n",
    "print('Maximum number of linear interations: {}'.format(ims.inner_maximum.get_data()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: moderate\n"
     ]
    }
   ],
   "source": [
    "# Complexity: Defines if the model can trates as linear or nonlinear problem.\n",
    "print('Complexity: {}'.format(ims.complexity.get_data()))\n",
    "# simple: Model can be trated as linear problem (confined units, linear stress packages, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: moderate\n"
     ]
    }
   ],
   "source": [
    "ims.complexity.set_data('moderate')\n",
    "print('Complexity: {}'.format(ims.complexity.get_data()))\n",
    "# moderate (several unconfined units, nonlinear stress packages, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton-Raphson solver\n",
    "This solver is recommended where traditional wet/drying numerical schemes does not get an acceptable solution due to convergence problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newton-Rhapson solver using under relaxation \n",
    "model.name_file.newtonoptions = ('UNDER_RELAXATION')\n",
    "# This option allows to under-relax the head where water level falls below bottom of cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing simulation...\n",
      "  writing simulation name file...\n",
      "  writing simulation tdis package...\n",
      "  writing ims package mf6_webinar...\n",
      "  writing model mf6_webinar...\n",
      "    writing model name file...\n",
      "    writing package disu...\n",
      "    writing package riv_0...\n",
      "    writing package wel...\n",
      "    writing package npf...\n",
      "    writing package ic...\n",
      "    writing package oc...\n",
      "FloPy is using the following  executable to run the model: C:/WRDAPP/mf6.0.4/mf6.0.4/bin/mf6.exe\n",
      "                                   MODFLOW 6\n",
      "                U.S. GEOLOGICAL SURVEY MODULAR HYDROLOGIC MODEL\n",
      "                            VERSION 6.0.4 03/13/2019\n",
      "\n",
      "   MODFLOW 6 compiled Mar 13 2019 12:37:09 with IFORT compiler (ver. 19.0.0)\n",
      "\n",
      "This software has been approved for release by the U.S. Geological \n",
      "Survey (USGS). Although the software has been subjected to rigorous \n",
      "review, the USGS reserves the right to update the software as needed \n",
      "pursuant to further analysis and review. No warranty, expressed or \n",
      "implied, is made by the USGS or the U.S. Government as to the \n",
      "functionality of the software and related material nor shall the \n",
      "fact of release constitute any such warranty. Furthermore, the \n",
      "software is released on condition that neither the USGS nor the U.S. \n",
      "Government shall be held liable for any damages resulting from its \n",
      "authorized or unauthorized use. Also refer to the USGS Water \n",
      "Resources Software User Rights Notice for complete use, copyright, \n",
      "and distribution information.\n",
      "\n",
      " Run start date and time (yyyy/mm/dd hh:mm:ss): 2019/07/12 13:20:07\n",
      "\n",
      " Writing simulation list file: mfsim.lst\n",
      " Using Simulation name file: mfsim.nam\n",
      "\n",
      "ERROR REPORT:\n",
      "\n",
      " MODEL **MF6_WEBINAR** PRODUCES AN ASYMMETRIC COEFFICIENT MATRIX, BUT THE     \n",
      "     CONJUGATE GRADIENT METHOD WAS SELECTED. USE BICGSTAB INSTEAD.\n",
      " ERROR OCCURRED WHILE READING FILE:\n",
      " D:\\CompartidaVB\\Modflow\\Webinar_2019\\modflow6\\mf6_webinar\\mf6_webinar.ims\n",
      " Stopping due to error(s)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, [])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write simulation\n",
    "sim.write_simulation()\n",
    "\n",
    "#run simulation\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing simulation...\n",
      "  writing simulation name file...\n",
      "  writing simulation tdis package...\n",
      "  writing ims package mf6_webinar...\n",
      "  writing model mf6_webinar...\n",
      "    writing model name file...\n",
      "    writing package disu...\n",
      "    writing package riv_0...\n",
      "    writing package wel...\n",
      "    writing package npf...\n",
      "    writing package ic...\n",
      "    writing package oc...\n"
     ]
    }
   ],
   "source": [
    "# Change linear acceleration method \n",
    "ims.linear_acceleration.set_data('BICGSTAB')\n",
    "# write simulation\n",
    "sim.write_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FloPy is using the following  executable to run the model: C:/WRDAPP/mf6.0.4/mf6.0.4/bin/mf6.exe\n",
      "                                   MODFLOW 6\n",
      "                U.S. GEOLOGICAL SURVEY MODULAR HYDROLOGIC MODEL\n",
      "                            VERSION 6.0.4 03/13/2019\n",
      "\n",
      "   MODFLOW 6 compiled Mar 13 2019 12:37:09 with IFORT compiler (ver. 19.0.0)\n",
      "\n",
      "This software has been approved for release by the U.S. Geological \n",
      "Survey (USGS). Although the software has been subjected to rigorous \n",
      "review, the USGS reserves the right to update the software as needed \n",
      "pursuant to further analysis and review. No warranty, expressed or \n",
      "implied, is made by the USGS or the U.S. Government as to the \n",
      "functionality of the software and related material nor shall the \n",
      "fact of release constitute any such warranty. Furthermore, the \n",
      "software is released on condition that neither the USGS nor the U.S. \n",
      "Government shall be held liable for any damages resulting from its \n",
      "authorized or unauthorized use. Also refer to the USGS Water \n",
      "Resources Software User Rights Notice for complete use, copyright, \n",
      "and distribution information.\n",
      "\n",
      " Run start date and time (yyyy/mm/dd hh:mm:ss): 2019/07/12 13:25:12\n",
      "\n",
      " Writing simulation list file: mfsim.lst\n",
      " Using Simulation name file: mfsim.nam\n",
      " Solving:  Stress period:     1    Time step:     1\n",
      " Run end date and time (yyyy/mm/dd hh:mm:ss): 2019/07/12 13:39:06\n",
      " Elapsed run time: 13 Minutes, 54.314 Seconds\n",
      "\n",
      " Normal termination of simulation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, [])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run simulation\n",
    "sim.run_simulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open results and save it on _vtk_ file\n",
    "The hydraulic heads data are saved on the _.hds_ file. We can get this data using the output_keys command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mf6_webinar', 'CBC', 'FLOW-JA-FACE')\n",
      "('mf6_webinar', 'CBC', 'WEL')\n",
      "('mf6_webinar', 'CBC', 'RIV')\n",
      "('mf6_webinar', 'HDS', 'HEAD')\n"
     ]
    }
   ],
   "source": [
    "keys = sim.simulation_data.mfdata.output_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2569.77268033 2565.46390276 2560.90141369 ... 2294.80674201 2291.68578815\n",
      " 2288.08941353]\n"
     ]
    }
   ],
   "source": [
    "# get all head data\n",
    "head = sim.simulation_data.mfdata[file_name, 'HDS', 'HEAD']\n",
    "head = head[0]\n",
    "print(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be noted that when Newton-Raphson method is used no cells will dry. Consequently, we have to mark all cell where head is below its bottom. For this, we create a numpy array where val=1 if head<bottom (dry cell) and val=0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "disu = model.get_package('disu') #First, we get DISU package from the model.\n",
    "bot = disu.bot.array # Second, we get cells bottom from DISU package.\n",
    "#mask = head < bot # Mask where val=True if head<bottom and val=False if not.\n",
    "\n",
    "dry_cells = np.array( head - bot, dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_dry-cells_ is the numpy array where val=1 if head<bottom (dry cell) and val=0 if not. Now, we are ready to load the _vtk_ file and add the head and dry data to visalizate in Paraview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the vtk source file.\n",
    "reader = vtk.vtkUnstructuredGridReader()\n",
    "reader.SetFileName(sim_location + file_name + '.vtk')\n",
    "reader.Update() # Needed because of GetScalarRange\n",
    "ugrid = reader.GetOutput()\n",
    "reader.CloseVTKFile()\n",
    "\n",
    "# Convert head array to vtk_array and save it on untructured grid (ugrid)\n",
    "heads = numpy_support.numpy_to_vtk(head.ravel(), deep=True, array_type=vtk.VTK_FLOAT)\n",
    "heads.SetName('Heads')\n",
    "ugrid.GetCellData().AddArray(heads)\n",
    "\n",
    "# Convert dry_cells array to vtk_array and save it on untructured grid (ugrid)\n",
    "dry_cells = numpy_support.numpy_to_vtk(dry_cells.ravel(), deep=True, array_type=vtk.VTK_FLOAT)\n",
    "dry_cells.SetName('Dry')\n",
    "ugrid.GetCellData().AddArray(dry_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we update the _vtk_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writerVTK = vtk.vtkUnstructuredGridWriter()\n",
    "writerVTK.SetInputData(ugrid)\n",
    "writerVTK.SetFileName(sim_location + file_name + '.vtk')\n",
    "writerVTK.Update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading units nodes\n",
    "Geomodelr exports a _.json_ file that containts a dictionary where the keys are the geological units names and their values correponds to id nodes of the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file name:\n",
      "D:/CompartidaVB/Modflow/Webinar_2019/modflow6/mf6_webinar/mf6_webinar.json\n",
      "\n",
      "Geological units: dict_keys(['E2p', 'K2p', 'E1ss', 'K2E1g', 'K2lt', 'E1si', 'K2cp', 'E2E3co', 'E1c', 'K2d'])\n",
      "Number of nodes of E2p: 44562\n",
      "Number of nodes of E1ss: 18317\n",
      "Number of nodes of E2E3co: 2866\n",
      "\n",
      "First 20 nodes of E2E3co: [2649, 2650, 2671, 3475, 3494, 3513, 3532, 3533, 3552, 3553]\n"
     ]
    }
   ],
   "source": [
    "json_file = sim_location + file_name + '.json'\n",
    "print('JSON file name:\\n{}\\n'.format(json_file))\n",
    "\n",
    "with open(json_file) as json_file:  \n",
    "    unit_nodes = json.load(json_file)\n",
    "\n",
    "print('Geological units: {}'.format(unit_nodes.keys()))\n",
    "print('Number of nodes of E2p: {}'.format(len(unit_nodes[u'K2p'])))\n",
    "print('Number of nodes of E1ss: {}'.format(len(unit_nodes[u'E1ss'])))\n",
    "print('Number of nodes of E2E3co: {}'.format(len(unit_nodes[u'E2E3co'])))\n",
    "print('\\nFirst 20 nodes of E2E3co: {}'.format(unit_nodes[u'E2E3co'][:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
